# EthicalCA
MAI TFM project

# Abstract
User experience questionnaires are used at the end of a playtesting session to assess the quality of video games and improve their design. Performing a survey after the experience can lead to the user not remembering details and undergo boring and survey fatigue. We propose to integrate the survey in-game, by means of a conversational agent. We aim at endowing this agent with a value-aligned behaviour, using our definition of the moral value of respect to guide the agent not to disturb the user engagement. Endowing this value by means of reinforcement learning and the ethical embedding algorithm, which redesigns an environment to promote ethical behaviour, ensuring the agent learns to pursue its individual objective while fulfilling the ethical objective. A review of the state-of-the-art showcases that the novelty of our work is twofold: firstly, the application of ethical embedding outside toy problems; and secondly, the enrichment of a survey oriented conversational agent with this moral value. Results highlight the advantages of the embedding of a moral value in front of an agent with no ethical notion, with the ethical agent improving to avoid disturbing engagement compared to the unethical counterpart, setting the pavement for future ethical conversational agents.
